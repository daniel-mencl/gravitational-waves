{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from src.models import DecoderTransformer, count_parameters\n",
    "from src.data import random_values, create_signals, sine, create_batches, add_noise\n",
    "from src.train import train_one_epoch, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T19:40:49.294483Z",
     "iopub.status.busy": "2025-12-15T19:40:49.294203Z",
     "iopub.status.idle": "2025-12-15T19:40:49.323212Z",
     "shell.execute_reply": "2025-12-15T19:40:49.322630Z",
     "shell.execute_reply.started": "2025-12-15T19:40:49.294461Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1581569"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 512\n",
    "\n",
    "def create_model(device):\n",
    "    return DecoderTransformer(\n",
    "        output_parameter_count=1,\n",
    "        d_model=256,\n",
    "        num_heads=16,\n",
    "        num_layers=3,\n",
    "        d_ff=512,\n",
    "        max_seq_length=MAX_SEQUENCE_LENGTH,\n",
    "        dropout=0.2\n",
    "    ).to(device)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "transformer = create_model(device)\n",
    "optim = torch.optim.Adam(transformer.parameters(), lr=0.0001)\n",
    "criterion = nn.MSELoss()\n",
    "count_parameters(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T19:40:51.440709Z",
     "iopub.status.busy": "2025-12-15T19:40:51.440440Z",
     "iopub.status.idle": "2025-12-15T19:40:51.446998Z",
     "shell.execute_reply": "2025-12-15T19:40:51.446328Z",
     "shell.execute_reply.started": "2025-12-15T19:40:51.440690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "TIME_STEP = 0.5 / MAX_SEQUENCE_LENGTH\n",
    "MIN_OMEGA = 80\n",
    "MAX_OMEGA = 120\n",
    "BATCH_SIZE = 128\n",
    "NOISE = 0.025\n",
    "\n",
    "def create_data(count: int):\n",
    "    frequencies_1 = random_values(count, MIN_OMEGA, MAX_OMEGA)\n",
    "    frequencies_2 = random_values(count, MIN_OMEGA, MAX_OMEGA)\n",
    "    frequencies_3 = random_values(count, MIN_OMEGA, MAX_OMEGA)\n",
    "    \n",
    "    phases_1 = random_values(count, 0, 2 * torch.pi)\n",
    "    phases_2 = random_values(count, 0, 2 * torch.pi)\n",
    "    phases_3 = random_values(count, 0, 2 * torch.pi)\n",
    "            \n",
    "    sine_1 = create_signals(\n",
    "        omegas=frequencies_1,\n",
    "        signal_function=sine,\n",
    "        length=MAX_SEQUENCE_LENGTH + 1,\n",
    "        time_step=TIME_STEP,\n",
    "        phases=phases_1\n",
    "    )\n",
    "        \n",
    "    sine_2 = create_signals(\n",
    "        omegas=frequencies_2,\n",
    "        signal_function=sine,\n",
    "        length=MAX_SEQUENCE_LENGTH + 1,\n",
    "        time_step=TIME_STEP,\n",
    "        phases=phases_2\n",
    "    )\n",
    "\n",
    "    sine_3 = create_signals(\n",
    "        omegas=frequencies_3,\n",
    "        signal_function=sine,\n",
    "        length=MAX_SEQUENCE_LENGTH + 1,\n",
    "        time_step=TIME_STEP,\n",
    "        phases=phases_3\n",
    "    )\n",
    "    \n",
    "    signals = (sine_1 + sine_2 + sine_3) / 3\n",
    "    values, next_value = signals.split((MAX_SEQUENCE_LENGTH, 1), dim=1)\n",
    "    values = add_noise(values, NOISE)\n",
    "    return create_batches([values, next_value], BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T19:40:53.981079Z",
     "iopub.status.busy": "2025-12-15T19:40:53.980354Z",
     "iopub.status.idle": "2025-12-15T19:45:43.117555Z",
     "shell.execute_reply": "2025-12-15T19:45:43.116897Z",
     "shell.execute_reply.started": "2025-12-15T19:40:53.981054Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "TRAIN_COUNT = 64_000\n",
    "EVAL_COUNT = 6_400\n",
    "\n",
    "eval_batched_values, eval_batched_parameters = create_data(EVAL_COUNT)\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    batched_values, batched_parameters = create_data(TRAIN_COUNT)\n",
    "    train_one_epoch(transformer, optim, criterion, device, batched_values, batched_parameters)\n",
    "    torch.save(transformer.state_dict(), f\"{i+1}.pt\")\n",
    "    evaluation = evaluate(transformer, criterion, device, eval_batched_values, eval_batched_parameters)\n",
    "    print(f\"Epoch {i + 1}: {evaluation}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
