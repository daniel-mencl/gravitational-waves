{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba40969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from src.models import DecoderTransformer, count_parameters\n",
    "from src.data import random_values, create_signals, sine, cosine_squared, create_batches\n",
    "from src.train import train_one_epoch, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbe649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 512\n",
    "\n",
    "def make_model(device):\n",
    "    return DecoderTransformer(\n",
    "        output_parameter_count=1, # if we were predicting multiple parameters, this would increase\n",
    "        d_model=128,\n",
    "        num_heads=16,\n",
    "        num_layers=2,\n",
    "        d_ff=512,\n",
    "        max_seq_length=MAX_SEQUENCE_LENGTH,\n",
    "        dropout=0.1\n",
    "    ).to(device)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "transformer = make_model(device)\n",
    "optim = torch.optim.Adam(transformer.parameters(), lr=0.0001)\n",
    "criterion = nn.L1Loss()\n",
    "count_parameters(transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b54fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_STEP = 0.5 / MAX_SEQUENCE_LENGTH\n",
    "MIN_OMEGA = 85\n",
    "MAX_OMEGA = 115\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "def create_data(count: int):\n",
    "    frequencies = random_values(count, MIN_OMEGA, MAX_OMEGA)\n",
    "    phases = random_values(count, 0, 2 * torch.pi)\n",
    "        \n",
    "    sines = create_signals(\n",
    "        omegas=frequencies,\n",
    "        signal_function=sine,\n",
    "        length=MAX_SEQUENCE_LENGTH,\n",
    "        time_step=TIME_STEP,\n",
    "        phases=phases\n",
    "    )\n",
    "    \n",
    "    only_100 = torch.ones(count) * 100\n",
    "    cosines = create_signals(\n",
    "        omegas=only_100,\n",
    "        signal_function=cosine_squared,\n",
    "        length=MAX_SEQUENCE_LENGTH,\n",
    "        time_step=TIME_STEP,\n",
    "        phases=phases\n",
    "    )\n",
    "    \n",
    "    values = 0.7 * sines + 0.3 * cosines # weighted average to not complicate the signal too much (the model is quite small) - the cosine part acts like noise\n",
    "    return create_batches([values, frequencies.reshape(-1, 1)], BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14b2d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "TRAIN_COUNT = 64_000\n",
    "EVAL_COUNT = 6_400\n",
    "\n",
    "eval_batched_values, eval_batched_parameters = create_data(EVAL_COUNT)\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    batched_values, batched_parameters = create_data(TRAIN_COUNT)\n",
    "    train_one_epoch(transformer, optim, criterion, device, batched_values, batched_parameters)\n",
    "    torch.save(transformer.state_dict(), f\"{i+1}.pt\")\n",
    "    evaluation = evaluate(transformer, criterion, device, eval_batched_values, eval_batched_parameters)\n",
    "    print(f\"Epoch {i + 1}: {evaluation}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
